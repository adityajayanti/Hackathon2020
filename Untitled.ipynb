{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask_bootstrap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-974d68ed8ba9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrender_template\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0murl_for\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjsonify\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwerkzeug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msecure_filename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mflask_bootstrap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBootstrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m#import matplotlib.pyplot as plt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase64\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'flask_bootstrap'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Nov  4 23:46:53 2020\n",
    "\n",
    "@author: Chanabasagoudap\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from flask import jsonify , send_from_directory, send_file\n",
    "from flask import Flask, render_template, request,url_for, flash, redirect, jsonify\n",
    "from werkzeug.utils import secure_filename\n",
    "from flask_bootstrap import Bootstrap\n",
    "#import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import time\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import data_preprocessing as dp\n",
    "import model_train as mt\n",
    "import inference as inf\n",
    "import model_train_reg as mt_r\n",
    "\n",
    "# creates a Flask application, named app\n",
    "app = Flask(__name__)\n",
    "Bootstrap(app)\n",
    "bootstrapLink= '<link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css\">'\n",
    "\n",
    "# a route where we will display a welcome message via an HTML template\n",
    "\n",
    "import os\n",
    "app.secret_key = \"secret key\"\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024\n",
    "\n",
    "# Get current path\n",
    "path = os.getcwd()\n",
    "# file Upload\n",
    "UPLOAD_FOLDER = os.path.join(path, 'uploads/train')\n",
    "TEST_FOLDER = os.path.join(path, 'uploads/test')\n",
    "DFProfile_FOLDER = os.path.join(path, 'uploads/DFProfile')\n",
    "\n",
    "# Make directory if uploads is not exists\n",
    "if not os.path.isdir(UPLOAD_FOLDER):\n",
    "    os.mkdir(UPLOAD_FOLDER)\n",
    "if not os.path.isdir(DFProfile_FOLDER):\n",
    "    os.mkdir(DFProfile_FOLDER)\n",
    "\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config[\"TEST_FOLDER\"] = TEST_FOLDER\n",
    "app.config['DFProfile_FOLDER'] = DFProfile_FOLDER\n",
    "\n",
    "\n",
    "# Allowed extension you can set your own\n",
    "ALLOWED_EXTENSIONS = set([\"csv\",\"xlsx\",\"json\"])\n",
    "\n",
    "###############################################################################\n",
    "# Check the file is having proper extension or not\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/upload_files', methods=['POST'])\n",
    "def upload_files():\n",
    "    if request.method == 'POST':\n",
    "        mypath = \"uploads/train\"\n",
    "        for root, dirs, files in os.walk(mypath):\n",
    "            for file in files:\n",
    "                os.remove(os.path.join(root, file))\n",
    "        if 'files[]' not in request.files:\n",
    "            flash('No file part')\n",
    "            return redirect(request.url)\n",
    "\n",
    "        files = request.files.getlist('files[]')\n",
    "        #print(len(files))\n",
    "        for file in files:\n",
    "            if file and allowed_file(file.filename):\n",
    "                filename = secure_filename(file.filename)\n",
    "                print(filename)\n",
    "                file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
    "\n",
    "        return render_template(\"index.html\")\n",
    "\n",
    "@app.route('/data_profiling', methods = ['GET', 'POST'])\n",
    "def data_profiling():\n",
    "    if request.method == 'POST':\n",
    "\n",
    "        if os.path.exists(\"uploads/DFProfile/DFReport.html\"):\n",
    "            os.remove(\"uploads/DFProfile/DFReport.html\")\n",
    "        \n",
    "        mypath = \"uploads/DFProfile\"\n",
    "        for root, dirs, files in os.walk(mypath):\n",
    "            for file in files:\n",
    "                os.remove(os.path.join(root, file))\n",
    "        f = request.files['file']\n",
    "        f.save(os.path.join(app.config['DFProfile_FOLDER'], f.filename))\n",
    "        \n",
    "        filename = None\n",
    "        for root, dirs, files in os.walk(mypath):\n",
    "            for file in files:\n",
    "                filename = file\n",
    "        \n",
    "        # #return render_template(\"results/DFReport.html\")\n",
    "        print(\"File Name\",filename)\n",
    "        \n",
    "        path = mypath + \"/\" +filename\n",
    "        print(\"Path:\",path)\n",
    "        if \".csv\" in filename:\n",
    "            datasetprofile = pd.read_csv(path)\n",
    "            profile = datasetprofile.profile_report(title='AiZen Data Profiling Report')\n",
    "            profile.to_file(output_file=\"uploads/DFProfile/DFReport.html\")\n",
    "        elif \".xlsx\" in filename:\n",
    "            print(\"Excel FIle\")\n",
    "            datasetprofile = pd.read_excel(path, sheet_name=0)\n",
    "            profile = datasetprofile.profile_report(title='AiZen Data Profiling Report')\n",
    "            profile.to_file(output_file=\"uploads/DFProfile/DFReport.html\")\n",
    "            \n",
    "        #return render_template(\"DFReport.html\")\n",
    "        #return send_file(\"uploads/DFProfile/DFReport.html\", attachment_filename=\"DFReport.html\")\n",
    "        return send_from_directory(mypath, \"DFReport.html\", as_attachment=True)\n",
    "\n",
    "def file_readers(training_path):\n",
    "    path, dirs, files = next(os.walk(training_path))\n",
    "    if len(files) == 3:\n",
    "        for filename in files:\n",
    "            if \".csv\" in filename:\n",
    "                dataset = pd.read_csv(training_path +\"/\"+ filename)\n",
    "            elif \".xlsx\" in filename and filename==\"Feature_Selected.xlsx\":\n",
    "                feature_selected = pd.read_excel(training_path +\"/\"+ filename , sheet_name=0)\n",
    "            elif \".xlsx\" in filename:\n",
    "                dataset = pd.read_excel(training_path +\"/\"+ filename , sheet_name=0)\n",
    "            elif \".json\" in filename:\n",
    "                with open(training_path + \"/\"+ filename) as f:\n",
    "                    fearure_info = json.load(f)\n",
    "\n",
    "        return dataset, feature_selected, fearure_info\n",
    "    else:\n",
    "        return \"Please upload all 3 files.\"\n",
    "\n",
    "\n",
    "@app.route('/train_classifier', methods = ['GET', 'POST'])\n",
    "def train_classifier():\n",
    "    \"\"\"\n",
    "    This API enable the user to train the classifier model by utilising the file present\n",
    "    in the folder \"uploads/train\".\n",
    "    dataset_dup = dp_dup.remove_duplicate_records(dataset)\n",
    "    dataset_nan = dp_nan.deal_with_nan(dataset_dup)\n",
    "    dataset_cat = dp_cat.deal_with_categorical_data(dataset_nan)\n",
    "    dataset_out = dp_out.deal_with_outlier(dataset_cat)\n",
    "    dataset_scale = dp_scale.scale_feature(dataset_out)\n",
    "\n",
    "    \"\"\"\n",
    "    if request.method == 'POST':\n",
    "        training_path = \"uploads/train\"\n",
    "        dataset, feature_selected, feature_info = file_readers(training_path)\n",
    "        \"\"\"\n",
    "        print(\"Dataset\",dataset.head(3))\n",
    "        print(\"feature_selected\",feature_selected)\n",
    "        print(\"fearure_info\",fearure_info)\n",
    "        \"\"\"\n",
    "       \n",
    "        # Getting Important columns from Feature Selected.xlsx\n",
    "        selectedFeature = list(feature_selected[feature_selected[\"Required\"] == True][\"Feature Name\"].values)\n",
    "        print(\"Feature Selected:\", selectedFeature)\n",
    "\n",
    "        # Getting the feature information from Feature Info.json\n",
    "        ignore_cols = feature_info[\"ignore_cols\"]\n",
    "        target_col = feature_info[\"target_col\"]\n",
    "        print(\"\\nIgnore Cols:\", ignore_cols)\n",
    "        print(\"\\nTarget Cols:\", target_col)\n",
    "\n",
    "        # Will remove the duplicates in dataset\n",
    "        dataset_dup = dp.remove_duplicate_records(dataset)\n",
    "\n",
    "         # Dataset as per the client data\n",
    "        print(\"Before :Shape of Dataframe :\", dataset.shape)\n",
    "\n",
    "        # Taking the selected features only after removal of duplicates.\n",
    "        target_var = dataset_dup[target_col]\n",
    "        dataset_dup = dataset_dup[selectedFeature].copy()\n",
    "\n",
    "        print(\"Length of target variable:\",len(target_var))\n",
    "        print(\"After :Shape of Dataframe after feature selection:\", dataset_dup.shape)\n",
    "\n",
    "\n",
    "        # Will deal with NaN value in dataset\n",
    "        dataset_nan = dp.deal_with_nan(dataset_dup)\n",
    "        #print(dataset_nan.shape)\n",
    "\n",
    "        # Need to scale the data\n",
    "        dataset_scaled = dp.feature_transformation(dataset_nan)\n",
    "        print(\"Scaled Dataset:\\n\",dataset_scaled)\n",
    "\n",
    "        # Now from here trainig starts\n",
    "        final_data = dataset_scaled.copy()\n",
    "        final_data[target_col] = target_var\n",
    "\n",
    "        # Perform K-Fold Cross Validation for training.\n",
    "\n",
    "        print(\"*********************************************\")\n",
    "        print(final_data.columns)\n",
    "        df_result = mt.train_classification_model(dataset_scaled, final_data, target_col)\n",
    "\n",
    "        result = \"Training is completed and accuracy is = \" + str(df_result)\n",
    "        \n",
    "        return result\n",
    "  \n",
    "    else:\n",
    "        return \"Only POST Method is allowed.\"\n",
    "\n",
    "@app.route('/train_regressor', methods = ['GET', 'POST'])\n",
    "def train_regressor():\n",
    "    if request.method == 'POST':\n",
    "        training_path = \"uploads/train\"\n",
    "        dataset, feature_selected, feature_info = file_readers(training_path)\n",
    "        \"\"\"\n",
    "        print(\"Dataset\",dataset.head(3))\n",
    "        print(\"feature_selected\",feature_selected)\n",
    "        print(\"fearure_info\",fearure_info)\n",
    "        \"\"\"\n",
    "       \n",
    "        # Getting Important columns from Feature Selected.xlsx\n",
    "        selectedFeature = list(feature_selected[feature_selected[\"Required\"] == True][\"Feature Name\"].values)\n",
    "        print(\"Feature Selected:\", selectedFeature)\n",
    "\n",
    "        # Getting the feature information from Feature Info.json\n",
    "        ignore_cols = feature_info[\"ignore_cols\"]\n",
    "        target_col = feature_info[\"target_col\"]\n",
    "        print(\"\\nIgnore Cols:\", ignore_cols)\n",
    "        print(\"\\nTarget Cols:\", target_col)\n",
    "\n",
    "        # Will remove the duplicates in dataset\n",
    "        dataset_dup = dp.remove_duplicate_records(dataset)\n",
    "\n",
    "         # Dataset as per the client data\n",
    "        print(\"Before :Shape of Dataframe :\", dataset.shape)\n",
    "\n",
    "        # Taking the selected features only after removal of duplicates.\n",
    "        target_var = dataset_dup[target_col]\n",
    "        dataset_dup = dataset_dup[selectedFeature].copy()\n",
    "\n",
    "        print(\"Length of target variable:\",len(target_var))\n",
    "        print(\"After :Shape of Dataframe after feature selection:\", dataset_dup.shape)\n",
    "\n",
    "\n",
    "        # Will deal with NaN value in dataset\n",
    "        dataset_nan = dp.deal_with_nan(dataset_dup)\n",
    "        #print(dataset_nan.shape)\n",
    "\n",
    "        # Need to scale the data\n",
    "        dataset_scaled = dp.feature_transformation(dataset_nan)\n",
    "        print(\"Scaled Dataset:\\n\",dataset_scaled)\n",
    "\n",
    "        # Now from here trainig starts\n",
    "        final_data = dataset_scaled.copy()\n",
    "        final_data[target_col] = target_var\n",
    "\n",
    "        print(\"*********************************************\")\n",
    "        print(final_data.columns)\n",
    "        df_result_1 = mt_r.train_regression_model(dataset_scaled, final_data, target_col)\n",
    "\n",
    "        result = \"Training is completed and rms is = \" + str(df_result_1)\n",
    "        return result\n",
    "    else:\n",
    "        return \"Only POST Method is allowed.\"\n",
    "      \n",
    "\n",
    "@app.route('/evaluate_model', methods = ['GET', 'POST'])\n",
    "def evaluate_model():\n",
    "    if request.method == 'POST':\n",
    "        # Need to worki on the Creation of model\n",
    "        if 'file' not in request.files:\n",
    "            flash('No file part')\n",
    "            return redirect(request.url)\n",
    "        file = request.files['file']\n",
    "        # if user does not select file, browser also\n",
    "        # submit an empty part without filename\n",
    "        if file.filename == '':\n",
    "            flash('No selected file')\n",
    "            return redirect(request.url)\n",
    "        if file and allowed_file(file.filename):\n",
    "            filename = secure_filename(file.filename)\n",
    "            file.save(os.path.join(app.config['TEST_FOLDER'], filename))\n",
    "        \n",
    "        path, dirs, files = next(os.walk(\"uploads/test\"))\n",
    "        print(len(files))\n",
    "        if len(files) == 1:\n",
    "            for filename in files:\n",
    "                path = \"uploads/test\" + \"/\" + filename\n",
    "                if \"csv\" in filename:\n",
    "                    test_data = pd.read_csv(path)\n",
    "                elif \"xlsx\" in filename:\n",
    "                    test_data = pd.read_excel(path)\n",
    "        \n",
    "        #print(test_data)\n",
    "        \n",
    "        training_path = \"uploads/train\"\n",
    "        dataset, feature_selected, feature_info = file_readers(training_path)\n",
    "       \n",
    "        # Getting Important columns from Feature Selected.xlsx\n",
    "        selectedFeature = list(feature_selected[feature_selected[\"Required\"] == True][\"Feature Name\"].values)\n",
    "        test_data = test_data[selectedFeature]\n",
    "\n",
    "        # Will deal with NaN value in dataset\n",
    "        dataset_nan = dp.deal_with_nan(test_data)\n",
    "        #print(dataset_nan.shape)\n",
    "\n",
    "        # Need to scale the data\n",
    "        dataset_scaled = dp.feature_transformation(dataset_nan)\n",
    "        print(\"Scaled Dataset:\\n\",dataset_scaled)\n",
    "\n",
    "        # Performing the forecasting based on the saved model\n",
    "        result = inf.perform_classification(dataset_scaled)\n",
    "        \n",
    "        path = \"results/\"\n",
    "        filename = \"AiZen_Predicted_value.xlsx\"\n",
    "        filepath = path + filename\n",
    "        result.to_excel(filepath)\n",
    "\n",
    "        return send_from_directory(path, filename, as_attachment=True)\n",
    "\n",
    "\n",
    "@app.route('/refresh', methods = ['GET', 'POST'])\n",
    "def refresh():\n",
    "    if request.method == 'POST':\n",
    "        # Need to worki on the Creation of model\n",
    "        \n",
    "        return \"Work in Progress\"\n",
    "\n",
    "# run the application\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "1>\n",
    "            div1 = \"<div style='font-size: 20px; font-weight: bold; color: blue; text-align: center; border-style: solid; border-color: black;'><img src='data:image/jpeg;base64,\"+encoded_string1+\"'/></div>\"    \n",
    "            div2 = \"<div style='font-size: 20px; font-weight: bold; color: blue; text-align: center; border-style: solid; border-color: black;'><img src='data:image/jpeg;base64,\"+encoded_string2+\"'/></div>\"    \n",
    "            div3 = \"<div style='font-size: 20px; font-weight: bold; color: blue; text-align: center; border-style: solid; border-color: black;'><img src='data:image/jpeg;base64,\"+encoded_string3+\"'/></div>\"    \n",
    "            div4 = \"<div style='font-size: 20px; font-weight: bold; color: blue; text-align: center; border-style: solid; border-color: black;'><img src='data:image/jpeg;base64,\"+encoded_string4+\"'/></div>\"    \n",
    "            div5 = \"<div style='font-size: 20px; font-weight: bold; color: blue; text-align: center; border-style: solid; border-color: black;'><img src='data:image/jpeg;base64,\"+encoded_string5+\"'/></div>\"    \n",
    "            div6 = \"<div style='font-size: 20px; font-weight: bold; color: blue; text-align: center; border-style: solid; border-color: black;'><img src='data:image/jpeg;base64,\"+encoded_string6+\"'/></div>\"\n",
    "           \n",
    "            div = div2+div3+div4+div5+div6+div1\n",
    "\n",
    "            \n",
    "     \n",
    "    return bootstrapLink +\"<div class='container container-fluid'><div class='panel panel-default'><div class='panel-heading text-center'><h3 class='panel-title'><strong>Sentiment Analysis</strong></h3></div><br>\" + div\n",
    "\n",
    "2>\n",
    "            div1 = \"<table border='1'><tr><th>Most famous Aspect Employee Talk About</th><tr><td>\"+str(aspect_count)+\"</td></tr></table>\"\n",
    "            div2 = \"<div style='font-size: 20px; font-weight: bold; color: blue; text-align: center; border-style: solid; border-color: black;'><p>\"+title4+\"<br><img src='data:image/jpeg;base64,\"+encoded_string4+\"'/></div>\"\n",
    "            return \"\"+div1+\"<br>\"+div2+\"\"\n",
    "\n",
    "\n",
    "3>\n",
    "# Visulization 1 ---- Feedback from each office Location\n",
    "            #tot_feedback_count = len(dataset.Branch)\n",
    "            viz_cnt,hitech_cnt, bachu_cnt, knodapur_cnt, kolhaput_cnt= 0, 0, 0, 0, 0\n",
    "            for location in dataset.Branch:\n",
    "                if location == \"Visakhapatnam\":\n",
    "                    viz_cnt += 1\n",
    "                if location == \"Hitech City\":\n",
    "                    hitech_cnt += 1\n",
    "                if location == \"Bachupally\":\n",
    "                    bachu_cnt += 1\n",
    "                if location == \"Kondapur\":\n",
    "                    knodapur_cnt += 1\n",
    "                if location == \"Kolhapur\":\n",
    "                    kolhaput_cnt += 1\n",
    "            \n",
    "            location = [\"Visakhapatnam\",\"Hitech\",\"Bachupally\",\"Kondapur\",\"Kolhapur\"]\n",
    "            count_index = np.arange(len(location)) \n",
    "            location_cnt = [viz_cnt,hitech_cnt, bachu_cnt,knodapur_cnt, kolhaput_cnt]\n",
    "            XLabel1 = \"MOURIT Tech Office Location\"\n",
    "            YLabel1 = \"Feedback from different Office Location\"\n",
    "            title1 = \"Feedback from Different Office Loaction of MOURI Tech\"\n",
    "            plot_img_addr1 = plot_bar_chart(count_index,location, location_cnt,XLabel1,YLabel1,title1)\n",
    "\n",
    "            # Calling function to extact the base64 fror title1\n",
    "            encoded_string1 = extract_base64(plot_img_addr1)\n",
    "                     \n",
    "            div1 = \"<div style='font-size: 20px; font-weight: bold; color: blue; text-align: center; border-style: solid; border-color: black;'><p>\"+title1+\"<br><img src='data:image/jpeg;base64,\"+encoded_string1+\"'/></div>\"\n",
    "            \n",
    "           # Visualization 2 :------  Internet Performacnce\n",
    "           \n",
    "            internet_sat , internet_unsat , internet_NA = 0, 0 ,0\n",
    "            for emotion in dataset[\"internet performance\"]:\n",
    "                if emotion == \"Yes\":\n",
    "                    internet_sat += 1\n",
    "                if emotion == \"No\":\n",
    "                    internet_unsat += 1\n",
    "                if emotion == \"N/A\":\n",
    "                    internet_NA += 1\n",
    "            \n",
    "            emotion = [\"Satisfied\", \"Unsatisfied\",\" Not Applicable\"]\n",
    "            emotion_cnt = np.arange(len(emotion))\n",
    "            internet_cnt = [internet_sat,internet_unsat, internet_NA]\n",
    "            XLabel2 = \" Happiness index\"\n",
    "            YLabel2 = \" Internet Performance of different Office Location\"\n",
    "            title2 = \"Overall MOURI Tech internet Performance\"\n",
    "            plot_img_addr2 = plot_bar_chart(emotion_cnt,emotion, internet_cnt,XLabel2,YLabel2,title2)\n",
    "            \n",
    "            # Calling function to extact the base64 fror title2\n",
    "            encoded_string2 = extract_base64(plot_img_addr2)\n",
    "            \n",
    "            div2 = \"<div style='font-size: 20px; font-weight: bold; color: blue; text-align: center; border-style: solid; border-color: black;'><p>\"+title2+\"<br><img src='data:image/jpeg;base64,\"+encoded_string2+\"'/></div>\"\n",
    "\n",
    "\n",
    "            # Visualization 3 :----------------------- Skype Zoom and WebEX connectivity\n",
    "            \n",
    "            szw_sat ,szw_unsat ,skw_NA = 0, 0, 0\n",
    "            \n",
    "            for connectivity in dataset[\"Skype/Zoom/Webex_Call_stabality\"]:\n",
    "                if connectivity ==\"Yes\":\n",
    "                    szw_sat += 1\n",
    "                if connectivity == \"No\":\n",
    "                    szw_unsat +=1\n",
    "                if connectivity ==\"N/A\":\n",
    "                    skw_NA += 1\n",
    "            \n",
    "            szw_cnt = [szw_sat, szw_unsat,skw_NA ]\n",
    "            XLabel3 = \" Happiness index\"\n",
    "            YLabel3 = \" Skype Zoom and WebEX connectivity different Office Location\"\n",
    "            title3 = \"Overall MOURI Tech Skype Zoom and WebEX connectivity  Performance\"\n",
    "            \n",
    "            #Plotting and saving a graph\n",
    "            plot_img_addr3 = plot_bar_chart(emotion_cnt,emotion, szw_cnt,XLabel3,YLabel3,title3)\n",
    "            # Calling function to extact the base64 fror title3\n",
    "            encoded_string3 = extract_base64(plot_img_addr3)\n",
    "            div3 = \"<div style='font-size: 20px; font-weight: bold; color: blue; text-align: center; border-style: solid; border-color: black;'><p>\"+title3+\"<br><img src='data:image/jpeg;base64,\"+encoded_string3+\"'/></div>\"\n",
    "            \n",
    "            return \"\"+div1+\"<br>\"+div2+\"<br>\"+div3+\"\"\n",
    "         \n",
    "4>\n",
    "numerical_data = dataset._get_numeric_data().columns\n",
    "            categorical_data = [c for i, c in enumerate(dataset.columns) if dataset.dtypes[i] in [np.object]]\n",
    "            Nan_Values = dataset.isnull().sum()\n",
    "\n",
    "            primary_keys = [] \n",
    "            \n",
    "            # Dynamically generating the possible Primary Keys\n",
    "            for feature in dataset.columns:\n",
    "                if len(dataset[feature]) == dataset[feature].nunique():\n",
    "                    primary_keys.append(feature)\n",
    "            #print(\"Primary Key\",primary_keys)\n",
    "            \n",
    "            # Dynamically generating the count of primary keys\n",
    "            pk_count_list = []\n",
    "            for feature in primary_keys:\n",
    "                pk_count_list.append(len(dataset[feature].unique()))\n",
    "            \n",
    "            # Column Analysis\n",
    "            column_analysis = {}\n",
    "            for features in dataset.columns:\n",
    "                column_analysis[features] = dataset[features].describe()\n",
    "            #print(\"Column Analysis\",column_analysis)\n",
    "            \n",
    "            result = bootstrapLink+\"<div class='container container-fluid'><div class='panel panel-default'><div class='panel-heading text-center'><h3 class='panel-title'> Types of Descriptive Analysis</h3></div><div class='panel-body'><div class='row'><div class='col-md-12'><table class='table table-bordered table-hover'><tr><th>Column with Numeric Values</th><th>Categorical Data</th><th>NaN values Columns</th><th>Primary Keys</th><th>Primary Keys Count List</th><th>Columns Analysis</th></tr><tr><td>\"+str(numerical_data)+\"</td><td>\"+str(categorical_data)+\"</td><td>\"+str(Nan_Values)+\"</td><td>\"+str(primary_keys)+\"</td><td>\"+str(pk_count_list)+\"</td><td>\"+str(column_analysis)+\"</td></tr></table></div></div></div></div></div>\"\n",
    "            \n",
    "            \n",
    "6> \n",
    "result = { \n",
    "                    \"Shape of Dataset\" : list(dataset.shape),\n",
    "                    \"Columns in Dataset\" : list(dataset.columns),\n",
    "                    \"Count of Columns\" : str(len(dataset.columns)),\n",
    "                    \"Need DataPreprocessing w.r.t NaN\" : str(dataset.isnull().values.any()),\n",
    "                    \"Total Null Value count\" : str(dataset.isnull().sum().sum()),\n",
    "                    \"Column with Null Values\" : list(dataset.columns[dataset.isnull().any()])}\n",
    "            #print(\"Result is \",result)\n",
    "            #return json.dumps(result)\n",
    "            return bootstrapLink+\"<div class='container container-fluid'><div class='panel panel-default'><div class='panel-heading text-center'><h3 class='panel-title'>Dataset Analysis</h3></div><div class='panel-body'><div class='row'><div class='col-md-12'><table class='table table-bordered table-hover'><tr><th>Shape of Dataset(rows/columns)</th><th>Columns in Dataset</th><th>Count of Columns</th><th>Need DataPreprocessing w.r.t NaN</th><th>Total Null Value count</th><th>Column with Null Values</th></tr><tr><td>\"+str(dataset.shape)+\"</td><td>\"+str(dataset.columns)+\"</td><td>\"+str(len(dataset.columns))+\"</td><td>\"+str(dataset.isnull().values.any())+\"</td><td>\"+str(dataset.isnull().sum().sum())+\"</td><td>\"+str(dataset.columns[dataset.isnull().any()])+\"</td></tr></table></div></div></div></div></div>\"                                     \n",
    "            \n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "        intermediate = \"\"\"\"\"\"\"\n",
    "        <div class=\"container container-fluid\">\n",
    "   <div class=\"panel panel-default\">\n",
    "      <div class=\"panel-heading text-center\">\n",
    "         <h3 class=\"panel-title\"><strong>Exploratory Data Analysis</strong></h3>\n",
    "      </div>\n",
    "      <div class=\"panel-body\">\n",
    "         <div class=\"row\">\n",
    "            <div class=\"col-md-12\">\n",
    "        \n",
    "        <div class=\"col-md-8\">\n",
    "                  <form action = \"/home\" method = \"POST\" enctype=\"multipart/form-data\">\n",
    "                     <p allign=\"Center\"> File Upload Successfull !!! </p>\n",
    "                     <br>\n",
    "                     <input type = \"submit\" style=\"width: 60%;\" value=\"Upload 3 Files\" class=\"btn-xclg btn btn-primary\"/>\n",
    "                  </form>\n",
    "               </div>\n",
    "\n",
    "            </div>\n",
    "         </div>\n",
    "      </div>\n",
    "   </div>\n",
    "</div>\n",
    "               \"\"\"\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
